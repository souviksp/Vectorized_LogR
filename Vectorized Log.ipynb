{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eh7EVITlReVX"
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score,f1_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=r'creditcard.csv'\n",
    "bd=pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first few entries of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2121,
     "status": "ok",
     "timestamp": 1569332749582,
     "user": {
      "displayName": "Souvik Pal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAZU-sQq4ASMRbOKQcV4QjPZeSKBqiQgtdQkWzM=s64",
      "userId": "10798680428956332703"
     },
     "user_tz": -330
    },
    "id": "FKW0BwvFSWYQ",
    "outputId": "c6f76acb-fa19-451f-be06-d56362c081ef"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " bd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 31 columns which we can convert into features for training our Logistic model. Henceforth, we'll use the term 'features' to refer to the independent variable columns. Note that the last column 'Class' is the response variable.\n",
    "\n",
    "Let's check the shape of the data to get an idea of how big of a dataset we're  handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the usability of each feature by using the info() function. This will give us an idea about the data types of the features and presence of null values in each column. This will help to proceed with data preparation or manipulation if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      "Time      284807 non-null float64\n",
      "V1        284807 non-null float64\n",
      "V2        284807 non-null float64\n",
      "V3        284807 non-null float64\n",
      "V4        284807 non-null float64\n",
      "V5        284807 non-null float64\n",
      "V6        284807 non-null float64\n",
      "V7        284807 non-null float64\n",
      "V8        284807 non-null float64\n",
      "V9        284807 non-null float64\n",
      "V10       284807 non-null float64\n",
      "V11       284807 non-null float64\n",
      "V12       284807 non-null float64\n",
      "V13       284807 non-null float64\n",
      "V14       284807 non-null float64\n",
      "V15       284807 non-null float64\n",
      "V16       284807 non-null float64\n",
      "V17       284807 non-null float64\n",
      "V18       284807 non-null float64\n",
      "V19       284807 non-null float64\n",
      "V20       284807 non-null float64\n",
      "V21       284807 non-null float64\n",
      "V22       284807 non-null float64\n",
      "V23       284807 non-null float64\n",
      "V24       284807 non-null float64\n",
      "V25       284807 non-null float64\n",
      "V26       284807 non-null float64\n",
      "V27       284807 non-null float64\n",
      "V28       284807 non-null float64\n",
      "Amount    284807 non-null float64\n",
      "Class     284807 non-null int64\n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "bd.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that all the features are of type float, even the column 'Time'. Also, there are no null values present in any features.\n",
    "Now that we know all the features are numerical, let's look at the statistical summary of each feature to get an ideaa of how they are distributed. This also gives us an idea whether the features are scaled by looking at the mean and the std. For this implementation of logistic regression, dataset has to be on a similar scale.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.050379e-14</td>\n",
       "      <td>1.000002</td>\n",
       "      <td>-1.996583</td>\n",
       "      <td>-0.855212</td>\n",
       "      <td>-0.213145</td>\n",
       "      <td>0.937217</td>\n",
       "      <td>1.642058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>1.958696</td>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-0.920373</td>\n",
       "      <td>0.018109</td>\n",
       "      <td>1.315642</td>\n",
       "      <td>2.454930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>1.651309</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-0.598550</td>\n",
       "      <td>0.065486</td>\n",
       "      <td>0.803724</td>\n",
       "      <td>22.057729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>1.516255</td>\n",
       "      <td>-48.325589</td>\n",
       "      <td>-0.890365</td>\n",
       "      <td>0.179846</td>\n",
       "      <td>1.027196</td>\n",
       "      <td>9.382558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>1.415869</td>\n",
       "      <td>-5.683171</td>\n",
       "      <td>-0.848640</td>\n",
       "      <td>-0.019847</td>\n",
       "      <td>0.743341</td>\n",
       "      <td>16.875344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>1.380247</td>\n",
       "      <td>-113.743307</td>\n",
       "      <td>-0.691597</td>\n",
       "      <td>-0.054336</td>\n",
       "      <td>0.611926</td>\n",
       "      <td>34.801666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V6</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>1.332271</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-0.768296</td>\n",
       "      <td>-0.274187</td>\n",
       "      <td>0.398565</td>\n",
       "      <td>73.301626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V7</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>1.237094</td>\n",
       "      <td>-43.557242</td>\n",
       "      <td>-0.554076</td>\n",
       "      <td>0.040103</td>\n",
       "      <td>0.570436</td>\n",
       "      <td>120.589494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V8</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>1.194353</td>\n",
       "      <td>-73.216718</td>\n",
       "      <td>-0.208630</td>\n",
       "      <td>0.022358</td>\n",
       "      <td>0.327346</td>\n",
       "      <td>20.007208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V9</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>1.098632</td>\n",
       "      <td>-13.434066</td>\n",
       "      <td>-0.643098</td>\n",
       "      <td>-0.051429</td>\n",
       "      <td>0.597139</td>\n",
       "      <td>15.594995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V10</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.768627e-15</td>\n",
       "      <td>1.088850</td>\n",
       "      <td>-24.588262</td>\n",
       "      <td>-0.535426</td>\n",
       "      <td>-0.092917</td>\n",
       "      <td>0.453923</td>\n",
       "      <td>23.745136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>9.170318e-16</td>\n",
       "      <td>1.020713</td>\n",
       "      <td>-4.797473</td>\n",
       "      <td>-0.762494</td>\n",
       "      <td>-0.032757</td>\n",
       "      <td>0.739593</td>\n",
       "      <td>12.018913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.810658e-15</td>\n",
       "      <td>0.999201</td>\n",
       "      <td>-18.683715</td>\n",
       "      <td>-0.405571</td>\n",
       "      <td>0.140033</td>\n",
       "      <td>0.618238</td>\n",
       "      <td>7.848392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V13</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.693438e-15</td>\n",
       "      <td>0.995274</td>\n",
       "      <td>-5.791881</td>\n",
       "      <td>-0.648539</td>\n",
       "      <td>-0.013568</td>\n",
       "      <td>0.662505</td>\n",
       "      <td>7.126883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V14</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.479045e-15</td>\n",
       "      <td>0.958596</td>\n",
       "      <td>-19.214325</td>\n",
       "      <td>-0.425574</td>\n",
       "      <td>0.050601</td>\n",
       "      <td>0.493150</td>\n",
       "      <td>10.526766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V15</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>3.482336e-15</td>\n",
       "      <td>0.915316</td>\n",
       "      <td>-4.498945</td>\n",
       "      <td>-0.582884</td>\n",
       "      <td>0.048072</td>\n",
       "      <td>0.648821</td>\n",
       "      <td>8.877742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V16</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.392007e-15</td>\n",
       "      <td>0.876253</td>\n",
       "      <td>-14.129855</td>\n",
       "      <td>-0.468037</td>\n",
       "      <td>0.066413</td>\n",
       "      <td>0.523296</td>\n",
       "      <td>17.315112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V17</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-7.528491e-16</td>\n",
       "      <td>0.849337</td>\n",
       "      <td>-25.162799</td>\n",
       "      <td>-0.483748</td>\n",
       "      <td>-0.065676</td>\n",
       "      <td>0.399675</td>\n",
       "      <td>9.253526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V18</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>4.328772e-16</td>\n",
       "      <td>0.838176</td>\n",
       "      <td>-9.498746</td>\n",
       "      <td>-0.498850</td>\n",
       "      <td>-0.003636</td>\n",
       "      <td>0.500807</td>\n",
       "      <td>5.041069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V19</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>9.049732e-16</td>\n",
       "      <td>0.814041</td>\n",
       "      <td>-7.213527</td>\n",
       "      <td>-0.456299</td>\n",
       "      <td>0.003735</td>\n",
       "      <td>0.458949</td>\n",
       "      <td>5.591971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V20</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>5.085503e-16</td>\n",
       "      <td>0.770925</td>\n",
       "      <td>-54.497720</td>\n",
       "      <td>-0.211721</td>\n",
       "      <td>-0.062481</td>\n",
       "      <td>0.133041</td>\n",
       "      <td>39.420904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V21</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>0.734524</td>\n",
       "      <td>-34.830382</td>\n",
       "      <td>-0.228395</td>\n",
       "      <td>-0.029450</td>\n",
       "      <td>0.186377</td>\n",
       "      <td>27.202839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V22</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>0.725702</td>\n",
       "      <td>-10.933144</td>\n",
       "      <td>-0.542350</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.528554</td>\n",
       "      <td>10.503090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V23</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>0.624460</td>\n",
       "      <td>-44.807735</td>\n",
       "      <td>-0.161846</td>\n",
       "      <td>-0.011193</td>\n",
       "      <td>0.147642</td>\n",
       "      <td>22.528412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V24</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>0.605647</td>\n",
       "      <td>-2.836627</td>\n",
       "      <td>-0.354586</td>\n",
       "      <td>0.040976</td>\n",
       "      <td>0.439527</td>\n",
       "      <td>4.584549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V25</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>0.521278</td>\n",
       "      <td>-10.295397</td>\n",
       "      <td>-0.317145</td>\n",
       "      <td>0.016594</td>\n",
       "      <td>0.350716</td>\n",
       "      <td>7.519589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V26</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>0.482227</td>\n",
       "      <td>-2.604551</td>\n",
       "      <td>-0.326984</td>\n",
       "      <td>-0.052139</td>\n",
       "      <td>0.240952</td>\n",
       "      <td>3.517346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V27</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>0.403632</td>\n",
       "      <td>-22.565679</td>\n",
       "      <td>-0.070840</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>0.091045</td>\n",
       "      <td>31.612198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V28</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>0.330083</td>\n",
       "      <td>-15.430084</td>\n",
       "      <td>-0.052960</td>\n",
       "      <td>0.011244</td>\n",
       "      <td>0.078280</td>\n",
       "      <td>33.847808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amount</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>3.202236e-16</td>\n",
       "      <td>1.000002</td>\n",
       "      <td>-0.353229</td>\n",
       "      <td>-0.330840</td>\n",
       "      <td>-0.265271</td>\n",
       "      <td>-0.044717</td>\n",
       "      <td>102.362243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.727486e-03</td>\n",
       "      <td>0.041527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count          mean       std         min       25%       50%  \\\n",
       "Time       284807.0 -1.050379e-14  1.000002   -1.996583 -0.855212 -0.213145   \n",
       "V1         284807.0  3.919560e-15  1.958696  -56.407510 -0.920373  0.018109   \n",
       "V2         284807.0  5.688174e-16  1.651309  -72.715728 -0.598550  0.065486   \n",
       "V3         284807.0 -8.769071e-15  1.516255  -48.325589 -0.890365  0.179846   \n",
       "V4         284807.0  2.782312e-15  1.415869   -5.683171 -0.848640 -0.019847   \n",
       "V5         284807.0 -1.552563e-15  1.380247 -113.743307 -0.691597 -0.054336   \n",
       "V6         284807.0  2.010663e-15  1.332271  -26.160506 -0.768296 -0.274187   \n",
       "V7         284807.0 -1.694249e-15  1.237094  -43.557242 -0.554076  0.040103   \n",
       "V8         284807.0 -1.927028e-16  1.194353  -73.216718 -0.208630  0.022358   \n",
       "V9         284807.0 -3.137024e-15  1.098632  -13.434066 -0.643098 -0.051429   \n",
       "V10        284807.0  1.768627e-15  1.088850  -24.588262 -0.535426 -0.092917   \n",
       "V11        284807.0  9.170318e-16  1.020713   -4.797473 -0.762494 -0.032757   \n",
       "V12        284807.0 -1.810658e-15  0.999201  -18.683715 -0.405571  0.140033   \n",
       "V13        284807.0  1.693438e-15  0.995274   -5.791881 -0.648539 -0.013568   \n",
       "V14        284807.0  1.479045e-15  0.958596  -19.214325 -0.425574  0.050601   \n",
       "V15        284807.0  3.482336e-15  0.915316   -4.498945 -0.582884  0.048072   \n",
       "V16        284807.0  1.392007e-15  0.876253  -14.129855 -0.468037  0.066413   \n",
       "V17        284807.0 -7.528491e-16  0.849337  -25.162799 -0.483748 -0.065676   \n",
       "V18        284807.0  4.328772e-16  0.838176   -9.498746 -0.498850 -0.003636   \n",
       "V19        284807.0  9.049732e-16  0.814041   -7.213527 -0.456299  0.003735   \n",
       "V20        284807.0  5.085503e-16  0.770925  -54.497720 -0.211721 -0.062481   \n",
       "V21        284807.0  1.537294e-16  0.734524  -34.830382 -0.228395 -0.029450   \n",
       "V22        284807.0  7.959909e-16  0.725702  -10.933144 -0.542350  0.006782   \n",
       "V23        284807.0  5.367590e-16  0.624460  -44.807735 -0.161846 -0.011193   \n",
       "V24        284807.0  4.458112e-15  0.605647   -2.836627 -0.354586  0.040976   \n",
       "V25        284807.0  1.453003e-15  0.521278  -10.295397 -0.317145  0.016594   \n",
       "V26        284807.0  1.699104e-15  0.482227   -2.604551 -0.326984 -0.052139   \n",
       "V27        284807.0 -3.660161e-16  0.403632  -22.565679 -0.070840  0.001342   \n",
       "V28        284807.0 -1.206049e-16  0.330083  -15.430084 -0.052960  0.011244   \n",
       "Amount     284807.0  3.202236e-16  1.000002   -0.353229 -0.330840 -0.265271   \n",
       "Class      284807.0  1.727486e-03  0.041527    0.000000  0.000000  0.000000   \n",
       "intercept  284807.0  1.000000e+00  0.000000    1.000000  1.000000  1.000000   \n",
       "\n",
       "                75%         max  \n",
       "Time       0.937217    1.642058  \n",
       "V1         1.315642    2.454930  \n",
       "V2         0.803724   22.057729  \n",
       "V3         1.027196    9.382558  \n",
       "V4         0.743341   16.875344  \n",
       "V5         0.611926   34.801666  \n",
       "V6         0.398565   73.301626  \n",
       "V7         0.570436  120.589494  \n",
       "V8         0.327346   20.007208  \n",
       "V9         0.597139   15.594995  \n",
       "V10        0.453923   23.745136  \n",
       "V11        0.739593   12.018913  \n",
       "V12        0.618238    7.848392  \n",
       "V13        0.662505    7.126883  \n",
       "V14        0.493150   10.526766  \n",
       "V15        0.648821    8.877742  \n",
       "V16        0.523296   17.315112  \n",
       "V17        0.399675    9.253526  \n",
       "V18        0.500807    5.041069  \n",
       "V19        0.458949    5.591971  \n",
       "V20        0.133041   39.420904  \n",
       "V21        0.186377   27.202839  \n",
       "V22        0.528554   10.503090  \n",
       "V23        0.147642   22.528412  \n",
       "V24        0.439527    4.584549  \n",
       "V25        0.350716    7.519589  \n",
       "V26        0.240952    3.517346  \n",
       "V27        0.091045   31.612198  \n",
       "V28        0.078280   33.847808  \n",
       "Amount    -0.044717  102.362243  \n",
       "Class      0.000000    1.000000  \n",
       "intercept  1.000000    1.000000  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the features are on a similar scale except for 'Time' and 'Amount'. We'll use StandardScaler() to scale just these two features. Note that 'Class' is the response variable and doesn't need to be scaled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UXqCObHKSWYs"
   },
   "outputs": [],
   "source": [
    "scale=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pHfXMTQXSWYx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\LENOVO\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "bd.Amount=pd.DataFrame(scale.fit_transform(bd.Amount.reshape(-1,1)))\n",
    "bd.Time=pd.DataFrame(scale.fit_transform(bd.Time.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.050379e-14</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>3.202236e-16</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.996583e+00</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>-3.532294e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.552120e-01</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>-3.308401e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-2.131453e-01</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>-2.652715e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.372174e-01</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>-4.471707e-02</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.642058e+00</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>1.023622e+02</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Time            V1            V2            V3            V4  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.050379e-14  3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15   \n",
       "std    1.000002e+00  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min   -1.996583e+00 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%   -8.552120e-01 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%   -2.131453e-01  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    9.372174e-01  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    1.642058e+00  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552563e-15  2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "           ...                 V21           V22           V23           V24  \\\n",
       "count      ...        2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean       ...        1.537294e-16  7.959909e-16  5.367590e-16  4.458112e-15   \n",
       "std        ...        7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min        ...       -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%        ...       -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%        ...       -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%        ...        1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max        ...        2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28        Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16  3.202236e-16   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01  1.000002e+00   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01 -3.532294e-01   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02 -3.308401e-01   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02 -2.652715e-01   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02 -4.471707e-02   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01  1.023622e+02   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that all the features are now scaled. \n",
    "\n",
    "Now we'll add a feature 'intercept' which will be a vector of inetger 1 for all examples (rows). This is for the constant intercept term in our regresiion equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c_upHDV3SWYz"
   },
   "outputs": [],
   "source": [
    "bd['intercept']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1369,
     "status": "ok",
     "timestamp": 1569332777589,
     "user": {
      "displayName": "Souvik Pal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAZU-sQq4ASMRbOKQcV4QjPZeSKBqiQgtdQkWzM=s64",
      "userId": "10798680428956332703"
     },
     "user_tz": -330
    },
    "id": "zS2z4sldSWY0",
    "outputId": "0a956642-8c9e-4a10-8adf-16e42014c183"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now split the entire dataset into train and test with an 80:20 split and separate the response variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5E-P8l6sWKB0"
   },
   "outputs": [],
   "source": [
    "train,test=train_test_split(bd,test_size=0.2)\n",
    "train.reset_index(drop=True,inplace=True)\n",
    "test.reset_index(drop=True,inplace=True)\n",
    "xtrain=train.drop(['Class'],1)\n",
    "ytrain=train['Class']\n",
    "xtest=test.drop(['Class'],1)\n",
    "ytest=test['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function 'sigmoid': Variable tranformation to keep output variable within 0 and 1. Takes the features as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "df8US2wmReWp"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return(1/(1+np.exp(-x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function 'hypothesis': Main hypothesis function that gives us the output variable given the input. Takes the parameters 'theta' and features 'x' as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tNDPeU8nReWq"
   },
   "outputs": [],
   "source": [
    "def hypothesis(theta,x):\n",
    "    z=np.dot(theta,x.transpose())\n",
    "    return sigmoid(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function 'cost_func': Logistic regression cost function that returns total error for a particular set of parameters. Takes the features 'X', response variable 'y' and parameters 'theta' as input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-tY2Cxd6SWY9"
   },
   "outputs": [],
   "source": [
    "def cost_func(X,y,theta,Lambda=0.1):\n",
    "    epsilon=1e-5\n",
    "    cost1=np.average(-y*np.log(hypothesis(theta,X))-(1-y)*np.log(1-hypothesis(theta,X)+1e-5))\n",
    "    cost2=Lambda/2*np.average(theta[1:]**2)\n",
    "    return cost1+cost2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function 'GD': Solver gradient descent that returns the parameters theta for which the cost function is minimum. Takes the features 'x', response variable 'y', learning rate 'alpha' and number of iteration as the input. The number of iterations acts as the stopping criteria for the algorithm. If 'progress' is set to True, it will show the cost value of each iteration. This will help us in diagnosing our model by giving us an idea whether our model is working correctly while the function is running. The cost should go down as the iterations proceed. And finally it plots the cost values against the number of iterations to give us a visual picture of how the cist fucntion decreased with number of iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5wlSxkyaSWY-"
   },
   "outputs": [],
   "source": [
    "def GD (x,y,progress=True,alpha=0.01,Lambda=0.01,iteration=1000):\n",
    "    theta=np.random.rand(len(x.loc[0]))\n",
    "    cost=[]\n",
    "\n",
    "    for i  in range(iteration):\n",
    "        cost_derivative1=1/len(x)*(np.dot(x.transpose(),(hypothesis(theta,x)-y)))\n",
    "    #cost_derivative2=np.average(np.dot(x.transpose(),(hypothesis(theta[0],x['intercept'])-y)))\n",
    "    #+Lambda*theta.iloc[:,1:])\n",
    "        theta=theta-alpha*cost_derivative1\n",
    "        cost.append(cost_func(x,y,theta))\n",
    "        if progress is True:\n",
    "            print('cost of iteration:',i,'=',cost[i])\n",
    "    #theta.iloc[:,1:]=theta.iloc[:,1:]-alpha*cost_derivative2\n",
    "    \n",
    "    plt.plot(cost)\n",
    "    plt.show()\n",
    "    return theta\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now run the gradient descent function on our training data to get the parameters that minimizes our cost function. We'll use alpha value as 0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost of iteration: 0 = 1.5961836872748012\n",
      "cost of iteration: 1 = 1.478737444286744\n",
      "cost of iteration: 2 = 1.3690246319199073\n",
      "cost of iteration: 3 = 1.2668854439380914\n",
      "cost of iteration: 4 = 1.172100769822674\n",
      "cost of iteration: 5 = 1.0844015930866227\n",
      "cost of iteration: 6 = 1.00347968992548\n",
      "cost of iteration: 7 = 0.9289982456701669\n",
      "cost of iteration: 8 = 0.8606000678828545\n",
      "cost of iteration: 9 = 0.7979144193974651\n",
      "cost of iteration: 10 = 0.7405658832553826\n",
      "cost of iteration: 11 = 0.6881819341540397\n",
      "cost of iteration: 12 = 0.6403979553170192\n",
      "cost of iteration: 13 = 0.596859969325351\n",
      "cost of iteration: 14 = 0.5572267007129632\n",
      "cost of iteration: 15 = 0.5211715245561018\n",
      "cost of iteration: 16 = 0.4883841857080815\n",
      "cost of iteration: 17 = 0.45857218461708676\n",
      "cost of iteration: 18 = 0.43146178020199805\n",
      "cost of iteration: 19 = 0.40679858776189076\n",
      "cost of iteration: 20 = 0.3843477743537199\n",
      "cost of iteration: 21 = 0.36389387894982983\n",
      "cost of iteration: 22 = 0.34524029882174184\n",
      "cost of iteration: 23 = 0.3282084915580372\n",
      "cost of iteration: 24 = 0.31263695640226913\n",
      "cost of iteration: 25 = 0.2983800726198432\n",
      "cost of iteration: 26 = 0.28530687112856884\n",
      "cost of iteration: 27 = 0.27329979829767104\n",
      "cost of iteration: 28 = 0.26225350977594886\n",
      "cost of iteration: 29 = 0.25207371659947503\n",
      "cost of iteration: 30 = 0.24267609673181992\n",
      "cost of iteration: 31 = 0.23398528000869628\n",
      "cost of iteration: 32 = 0.22593391095932008\n",
      "cost of iteration: 33 = 0.21846179116981732\n",
      "cost of iteration: 34 = 0.2115151004975942\n",
      "cost of iteration: 35 = 0.20504569454674637\n",
      "cost of iteration: 36 = 0.1990104744022099\n",
      "cost of iteration: 37 = 0.19337082368138342\n",
      "cost of iteration: 38 = 0.1880921074413041\n",
      "cost of iteration: 39 = 0.18314322729777657\n",
      "cost of iteration: 40 = 0.17849622718446012\n",
      "cost of iteration: 41 = 0.17412594442561\n",
      "cost of iteration: 42 = 0.17000970114992747\n",
      "cost of iteration: 43 = 0.16612703148410954\n",
      "cost of iteration: 44 = 0.16245944039686755\n",
      "cost of iteration: 45 = 0.15899019049286045\n",
      "cost of iteration: 46 = 0.15570411346530086\n",
      "cost of iteration: 47 = 0.1525874432959421\n",
      "cost of iteration: 48 = 0.14962766863561164\n",
      "cost of iteration: 49 = 0.1468134021041998\n",
      "cost of iteration: 50 = 0.14413426451566963\n",
      "cost of iteration: 51 = 0.1415807822638231\n",
      "cost of iteration: 52 = 0.13914429630359268\n",
      "cost of iteration: 53 = 0.1368168813373636\n",
      "cost of iteration: 54 = 0.1345912739728522\n",
      "cost of iteration: 55 = 0.1324608087630424\n",
      "cost of iteration: 56 = 0.13041936117169153\n",
      "cost of iteration: 57 = 0.12846129662988526\n",
      "cost of iteration: 58 = 0.1265814249589672\n",
      "cost of iteration: 59 = 0.12477495953195203\n",
      "cost of iteration: 60 = 0.12303748062910924\n",
      "cost of iteration: 61 = 0.12136490251457174\n",
      "cost of iteration: 62 = 0.11975344382101885\n",
      "cost of iteration: 63 = 0.11819960088042367\n",
      "cost of iteration: 64 = 0.11670012368220783\n",
      "cost of iteration: 65 = 0.11525199417736584\n",
      "cost of iteration: 66 = 0.11385240667935578\n",
      "cost of iteration: 67 = 0.11249875014070314\n",
      "cost of iteration: 68 = 0.11118859210898484\n",
      "cost of iteration: 69 = 0.10991966418767483\n",
      "cost of iteration: 70 = 0.10868984884661562\n",
      "cost of iteration: 71 = 0.10749716744396431\n",
      "cost of iteration: 72 = 0.10633976933659703\n",
      "cost of iteration: 73 = 0.10521592196937338\n",
      "cost of iteration: 74 = 0.1041240018455554\n",
      "cost of iteration: 75 = 0.10306248629122049\n",
      "cost of iteration: 76 = 0.10202994593585457\n",
      "cost of iteration: 77 = 0.10102503783960114\n",
      "cost of iteration: 78 = 0.10004649920499606\n",
      "cost of iteration: 79 = 0.09909314161754318\n",
      "cost of iteration: 80 = 0.09816384576528112\n",
      "cost of iteration: 81 = 0.09725755659264036\n",
      "cost of iteration: 82 = 0.09637327884846927\n",
      "cost of iteration: 83 = 0.09551007299218105\n",
      "cost of iteration: 84 = 0.09466705142560373\n",
      "cost of iteration: 85 = 0.09384337502135078\n",
      "cost of iteration: 86 = 0.09303824992141449\n",
      "cost of iteration: 87 = 0.09225092458226555\n",
      "cost of iteration: 88 = 0.09148068704504397\n",
      "cost of iteration: 89 = 0.09072686241148961\n",
      "cost of iteration: 90 = 0.08998881050810892\n",
      "cost of iteration: 91 = 0.08926592372272858\n",
      "cost of iteration: 92 = 0.08855762499907367\n",
      "cost of iteration: 93 = 0.08786336597634377\n",
      "cost of iteration: 94 = 0.0871826252619601\n",
      "cost of iteration: 95 = 0.08651490682673876\n",
      "cost of iteration: 96 = 0.08585973851271808\n",
      "cost of iteration: 97 = 0.08521667064474814\n",
      "cost of iteration: 98 = 0.08458527473774319\n",
      "cost of iteration: 99 = 0.08396514229221674\n",
      "cost of iteration: 100 = 0.0833558836713678\n",
      "cost of iteration: 101 = 0.08275712705357645\n",
      "cost of iteration: 102 = 0.0821685174547026\n",
      "cost of iteration: 103 = 0.08158971581506724\n",
      "cost of iteration: 104 = 0.08102039814643867\n",
      "cost of iteration: 105 = 0.08046025473475249\n",
      "cost of iteration: 106 = 0.07990898939466136\n",
      "cost of iteration: 107 = 0.07936631877235326\n",
      "cost of iteration: 108 = 0.07883197169338649\n",
      "cost of iteration: 109 = 0.07830568855258131\n",
      "cost of iteration: 110 = 0.07778722074327371\n",
      "cost of iteration: 111 = 0.07727633012348856\n",
      "cost of iteration: 112 = 0.07677278851682462\n",
      "cost of iteration: 113 = 0.07627637724606667\n",
      "cost of iteration: 114 = 0.07578688669775448\n",
      "cost of iteration: 115 = 0.07530411591614697\n",
      "cost of iteration: 116 = 0.0748278722252236\n",
      "cost of iteration: 117 = 0.07435797087757273\n",
      "cost of iteration: 118 = 0.07389423472922703\n",
      "cost of iteration: 119 = 0.07343649393972698\n",
      "cost of iteration: 120 = 0.07298458569693228\n",
      "cost of iteration: 121 = 0.07253835396636016\n",
      "cost of iteration: 122 = 0.07209764926512482\n",
      "cost of iteration: 123 = 0.0716623284608888\n",
      "cost of iteration: 124 = 0.07123225459663357\n",
      "cost of iteration: 125 = 0.07080729674252957\n",
      "cost of iteration: 126 = 0.0703873298767588\n",
      "cost of iteration: 127 = 0.06997223479784583\n",
      "cost of iteration: 128 = 0.06956189807192265\n",
      "cost of iteration: 129 = 0.06915621201943845\n",
      "cost of iteration: 130 = 0.06875507474718513\n",
      "cost of iteration: 131 = 0.0683583902332217\n",
      "cost of iteration: 132 = 0.06796606847443558\n",
      "cost of iteration: 133 = 0.0675780257091943\n",
      "cost of iteration: 134 = 0.06719418473094663\n",
      "cost of iteration: 135 = 0.06681447531288597\n",
      "cost of iteration: 136 = 0.06643883476904784\n",
      "cost of iteration: 137 = 0.0660672086836285\n",
      "cost of iteration: 138 = 0.0656995518479686\n",
      "cost of iteration: 139 = 0.06533582945349257\n",
      "cost of iteration: 140 = 0.06497601859858387\n",
      "cost of iteration: 141 = 0.06462011017703359\n",
      "cost of iteration: 142 = 0.06426811122353168\n",
      "cost of iteration: 143 = 0.06392004779441565\n",
      "cost of iteration: 144 = 0.06357596845409502\n",
      "cost of iteration: 145 = 0.06323594841081064\n",
      "cost of iteration: 146 = 0.06290009428789027\n",
      "cost of iteration: 147 = 0.06256854941413914\n",
      "cost of iteration: 148 = 0.0622414993563329\n",
      "cost of iteration: 149 = 0.06191917719431558\n",
      "cost of iteration: 150 = 0.061601867774414884\n",
      "cost of iteration: 151 = 0.06128990992722934\n",
      "cost of iteration: 152 = 0.060983695500207005\n",
      "cost of iteration: 153 = 0.060683664146839726\n",
      "cost of iteration: 154 = 0.0603902931937644\n",
      "cost of iteration: 155 = 0.06010408251255256\n",
      "cost of iteration: 156 = 0.05982553497314885\n",
      "cost of iteration: 157 = 0.059555133579031735\n",
      "cost of iteration: 158 = 0.05929331677958585\n",
      "cost of iteration: 159 = 0.059040453882233196\n",
      "cost of iteration: 160 = 0.058796823014716566\n",
      "cost of iteration: 161 = 0.05856259445921938\n",
      "cost of iteration: 162 = 0.058337821920193156\n",
      "cost of iteration: 163 = 0.05812244313186103\n",
      "cost of iteration: 164 = 0.057916289429909305\n",
      "cost of iteration: 165 = 0.057719102194610114\n",
      "cost of iteration: 166 = 0.05753055307778979\n",
      "cost of iteration: 167 = 0.05735026489740326\n",
      "cost of iteration: 168 = 0.05717783080458759\n",
      "cost of iteration: 169 = 0.05701283035475781\n",
      "cost of iteration: 170 = 0.05685484204897223\n",
      "cost of iteration: 171 = 0.056703452547388636\n",
      "cost of iteration: 172 = 0.05655826307151943\n",
      "cost of iteration: 173 = 0.05641889358917146\n",
      "cost of iteration: 174 = 0.05628498532195614\n",
      "cost of iteration: 175 = 0.056156202013534745\n",
      "cost of iteration: 176 = 0.0560322302951483\n",
      "cost of iteration: 177 = 0.05591277940241146\n",
      "cost of iteration: 178 = 0.055797580436021135\n",
      "cost of iteration: 179 = 0.05568638531442423\n",
      "cost of iteration: 180 = 0.05557896553315189\n",
      "cost of iteration: 181 = 0.05547511081937511\n",
      "cost of iteration: 182 = 0.05537462774887218\n",
      "cost of iteration: 183 = 0.05527733837484333\n",
      "cost of iteration: 184 = 0.05518307890334131\n",
      "cost of iteration: 185 = 0.0550916984382297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost of iteration: 186 = 0.05500305780929122\n",
      "cost of iteration: 187 = 0.0549170284900905\n",
      "cost of iteration: 188 = 0.05483349160711884\n",
      "cost of iteration: 189 = 0.05475233703824995\n",
      "cost of iteration: 190 = 0.054673462596279185\n",
      "cost of iteration: 191 = 0.05459677329199315\n",
      "cost of iteration: 192 = 0.054522180670565135\n",
      "cost of iteration: 193 = 0.05444960221488471\n",
      "cost of iteration: 194 = 0.05437896080954918\n",
      "cost of iteration: 195 = 0.05431018425954978\n",
      "cost of iteration: 196 = 0.05424320485809471\n",
      "cost of iteration: 197 = 0.05417795899846675\n",
      "cost of iteration: 198 = 0.05411438682527772\n",
      "cost of iteration: 199 = 0.054052431920932786\n",
      "cost of iteration: 200 = 0.05399204102354329\n",
      "cost of iteration: 201 = 0.05393316377291794\n",
      "cost of iteration: 202 = 0.053875752481620555\n",
      "cost of iteration: 203 = 0.05381976192840542\n",
      "cost of iteration: 204 = 0.05376514917163205\n",
      "cost of iteration: 205 = 0.05371187338052181\n",
      "cost of iteration: 206 = 0.05365989568235245\n",
      "cost of iteration: 207 = 0.053609179023894414\n",
      "cost of iteration: 208 = 0.05355968804557947\n",
      "cost of iteration: 209 = 0.05351138896705835\n",
      "cost of iteration: 210 = 0.05346424948295183\n",
      "cost of iteration: 211 = 0.05341823866773271\n",
      "cost of iteration: 212 = 0.053373326888792885\n",
      "cost of iteration: 213 = 0.053329485726855405\n",
      "cost of iteration: 214 = 0.05328668790298434\n",
      "cost of iteration: 215 = 0.05324490721152762\n",
      "cost of iteration: 216 = 0.05320411845840326\n",
      "cost of iteration: 217 = 0.05316429740420238\n",
      "cost of iteration: 218 = 0.05312542071164256\n",
      "cost of iteration: 219 = 0.0530874658969553\n",
      "cost of iteration: 220 = 0.053050411284836466\n",
      "cost of iteration: 221 = 0.0530142359666302\n",
      "cost of iteration: 222 = 0.052978919761450805\n",
      "cost of iteration: 223 = 0.052944443179979817\n",
      "cost of iteration: 224 = 0.05291078739070261\n",
      "cost of iteration: 225 = 0.052877934188373776\n",
      "cost of iteration: 226 = 0.05284586596452247\n",
      "cost of iteration: 227 = 0.052814565679827674\n",
      "cost of iteration: 228 = 0.05278401683821124\n",
      "cost of iteration: 229 = 0.05275420346251071\n",
      "cost of iteration: 230 = 0.05272511007160837\n",
      "cost of iteration: 231 = 0.05269672165890395\n",
      "cost of iteration: 232 = 0.05266902367202991\n",
      "cost of iteration: 233 = 0.05264200199371666\n",
      "cost of iteration: 234 = 0.052615642923724615\n",
      "cost of iteration: 235 = 0.052589933161766335\n",
      "cost of iteration: 236 = 0.05256485979134963\n",
      "cost of iteration: 237 = 0.05254041026447796\n",
      "cost of iteration: 238 = 0.0525165723871499\n",
      "cost of iteration: 239 = 0.05249333430560473\n",
      "cost of iteration: 240 = 0.05247068449326476\n",
      "cost of iteration: 241 = 0.05244861173832975\n",
      "cost of iteration: 242 = 0.05242710513198162\n",
      "cost of iteration: 243 = 0.05240615405716141\n",
      "cost of iteration: 244 = 0.052385748177883065\n",
      "cost of iteration: 245 = 0.05236587742905112\n",
      "cost of iteration: 246 = 0.05234653200675225\n",
      "cost of iteration: 247 = 0.05232770235899228\n",
      "cost of iteration: 248 = 0.052309379176852785\n",
      "cost of iteration: 249 = 0.052291553386042675\n",
      "cost of iteration: 250 = 0.052274216138822424\n",
      "cost of iteration: 251 = 0.05225735880627973\n",
      "cost of iteration: 252 = 0.05224097297093705\n",
      "cost of iteration: 253 = 0.05222505041967267\n",
      "cost of iteration: 254 = 0.05220958313693809\n",
      "cost of iteration: 255 = 0.05219456329825613\n",
      "cost of iteration: 256 = 0.05217998326398428\n",
      "cost of iteration: 257 = 0.052165835573329995\n",
      "cost of iteration: 258 = 0.05215211293860424\n",
      "cost of iteration: 259 = 0.05213880823970181\n",
      "cost of iteration: 260 = 0.05212591451879624\n",
      "cost of iteration: 261 = 0.05211342497523945\n",
      "cost of iteration: 262 = 0.05210133296065547\n",
      "cost of iteration: 263 = 0.05208963197421934\n",
      "cost of iteration: 264 = 0.05207831565811229\n",
      "cost of iteration: 265 = 0.05206737779314506\n",
      "cost of iteration: 266 = 0.052056812294541746\n",
      "cost of iteration: 267 = 0.052046613207876916\n",
      "cost of iteration: 268 = 0.05203677470515949\n",
      "cost of iteration: 269 = 0.05202729108105689\n",
      "cost of iteration: 270 = 0.05201815674925389\n",
      "cost of iteration: 271 = 0.05200936623894023\n",
      "cost of iteration: 272 = 0.05200091419142233\n",
      "cost of iteration: 273 = 0.051992795356853874\n",
      "cost of iteration: 274 = 0.05198500459108088\n",
      "cost of iteration: 275 = 0.051977536852597137\n",
      "cost of iteration: 276 = 0.05197038719960549\n",
      "cost of iteration: 277 = 0.051963550787181755\n",
      "cost of iteration: 278 = 0.05195702286453732\n",
      "cost of iteration: 279 = 0.051950798772377016\n",
      "cost of iteration: 280 = 0.05194487394034916\n",
      "cost of iteration: 281 = 0.051939243884584624\n",
      "cost of iteration: 282 = 0.051933904205322026\n",
      "cost of iteration: 283 = 0.051928850584616\n",
      "cost of iteration: 284 = 0.051924078784126235\n",
      "cost of iteration: 285 = 0.05191958464298431\n",
      "cost of iteration: 286 = 0.05191536407573585\n",
      "cost of iteration: 287 = 0.0519114130703558\n",
      "cost of iteration: 288 = 0.051907727686334185\n",
      "cost of iteration: 289 = 0.05190430405283009\n",
      "cost of iteration: 290 = 0.05190113836689168\n",
      "cost of iteration: 291 = 0.051898226891739965\n",
      "cost of iteration: 292 = 0.05189556595511426\n",
      "cost of iteration: 293 = 0.05189315194767706\n",
      "cost of iteration: 294 = 0.05189098132147633\n",
      "cost of iteration: 295 = 0.05188905058846331\n",
      "cost of iteration: 296 = 0.051887356319063535\n",
      "cost of iteration: 297 = 0.051885895140799304\n",
      "cost of iteration: 298 = 0.05188466373696175\n",
      "cost of iteration: 299 = 0.05188365884533038\n",
      "cost of iteration: 300 = 0.05188287725693835\n",
      "cost of iteration: 301 = 0.05188231581488176\n",
      "cost of iteration: 302 = 0.05188197141317108\n",
      "cost of iteration: 303 = 0.05188184099562291\n",
      "cost of iteration: 304 = 0.05188192155479061\n",
      "cost of iteration: 305 = 0.051882210130931986\n",
      "cost of iteration: 306 = 0.0518827038110124\n",
      "cost of iteration: 307 = 0.05188339972774199\n",
      "cost of iteration: 308 = 0.05188429505864521\n",
      "cost of iteration: 309 = 0.051885387025161496\n",
      "cost of iteration: 310 = 0.0518866728917754\n",
      "cost of iteration: 311 = 0.051888149965175184\n",
      "cost of iteration: 312 = 0.05188981559343813\n",
      "cost of iteration: 313 = 0.0518916671652418\n",
      "cost of iteration: 314 = 0.05189370210909963\n",
      "cost of iteration: 315 = 0.05189591789262002\n",
      "cost of iteration: 316 = 0.05189831202178762\n",
      "cost of iteration: 317 = 0.051900882040265814\n",
      "cost of iteration: 318 = 0.051903625528719514\n",
      "cost of iteration: 319 = 0.05190654010415709\n",
      "cost of iteration: 320 = 0.05190962341929081\n",
      "cost of iteration: 321 = 0.05191287316191457\n",
      "cost of iteration: 322 = 0.051916287054298405\n",
      "cost of iteration: 323 = 0.05191986285259891\n",
      "cost of iteration: 324 = 0.051923598346284655\n",
      "cost of iteration: 325 = 0.0519274913575761\n",
      "cost of iteration: 326 = 0.05193153974089934\n",
      "cost of iteration: 327 = 0.05193574138235284\n",
      "cost of iteration: 328 = 0.05194009419918679\n",
      "cost of iteration: 329 = 0.051944596139294336\n",
      "cost of iteration: 330 = 0.05194924518071442\n",
      "cost of iteration: 331 = 0.05195403933114526\n",
      "cost of iteration: 332 = 0.05195897662746847\n",
      "cost of iteration: 333 = 0.05196405513528317\n",
      "cost of iteration: 334 = 0.05196927294844951\n",
      "cost of iteration: 335 = 0.05197462818864153\n",
      "cost of iteration: 336 = 0.05198011900490865\n",
      "cost of iteration: 337 = 0.05198574357324575\n",
      "cost of iteration: 338 = 0.0519915000961712\n",
      "cost of iteration: 339 = 0.05199738680231278\n",
      "cost of iteration: 340 = 0.052003401946001004\n",
      "cost of iteration: 341 = 0.052009543806869736\n",
      "cost of iteration: 342 = 0.05201581068946369\n",
      "cost of iteration: 343 = 0.05202220092285273\n",
      "cost of iteration: 344 = 0.052028712860252554\n",
      "cost of iteration: 345 = 0.0520353448786517\n",
      "cost of iteration: 346 = 0.052042095378444696\n",
      "cost of iteration: 347 = 0.05204896278307095\n",
      "cost of iteration: 348 = 0.05205594553865951\n",
      "cost of iteration: 349 = 0.05206304211367932\n",
      "cost of iteration: 350 = 0.05207025099859487\n",
      "cost of iteration: 351 = 0.05207757070552715\n",
      "cost of iteration: 352 = 0.052084999767919776\n",
      "cost of iteration: 353 = 0.05209253674021004\n",
      "cost of iteration: 354 = 0.05210018019750501\n",
      "cost of iteration: 355 = 0.05210792873526234\n",
      "cost of iteration: 356 = 0.052115780968975844\n",
      "cost of iteration: 357 = 0.05212373553386566\n",
      "cost of iteration: 358 = 0.052131791084572957\n",
      "cost of iteration: 359 = 0.05213994629485919\n",
      "cost of iteration: 360 = 0.05214819985730963\n",
      "cost of iteration: 361 = 0.05215655048304127\n",
      "cost of iteration: 362 = 0.052164996901414996\n",
      "cost of iteration: 363 = 0.05217353785975199\n",
      "cost of iteration: 364 = 0.05218217212305419\n",
      "cost of iteration: 365 = 0.0521908984737289\n",
      "cost of iteration: 366 = 0.052199715711317506\n",
      "cost of iteration: 367 = 0.052208622652228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost of iteration: 368 = 0.05221761812947168\n",
      "cost of iteration: 369 = 0.05222670099240356\n",
      "cost of iteration: 370 = 0.0522358701064668\n",
      "cost of iteration: 371 = 0.05224512435294078\n",
      "cost of iteration: 372 = 0.05225446262869315\n",
      "cost of iteration: 373 = 0.052263883845935485\n",
      "cost of iteration: 374 = 0.052273386931982684\n",
      "cost of iteration: 375 = 0.05228297082901602\n",
      "cost of iteration: 376 = 0.05229263449384987\n",
      "cost of iteration: 377 = 0.05230237689770197\n",
      "cost of iteration: 378 = 0.05231219702596728\n",
      "cost of iteration: 379 = 0.05232209387799529\n",
      "cost of iteration: 380 = 0.05233206646687091\n",
      "cost of iteration: 381 = 0.05234211381919871\n",
      "cost of iteration: 382 = 0.05235223497489064\n",
      "cost of iteration: 383 = 0.05236242898695704\n",
      "cost of iteration: 384 = 0.05237269492130108\n",
      "cost of iteration: 385 = 0.05238303185651645\n",
      "cost of iteration: 386 = 0.05239343888368822\n",
      "cost of iteration: 387 = 0.05240391510619713\n",
      "cost of iteration: 388 = 0.052414459639526796\n",
      "cost of iteration: 389 = 0.05242507161107431\n",
      "cost of iteration: 390 = 0.05243575015996384\n",
      "cost of iteration: 391 = 0.05244649443686311\n",
      "cost of iteration: 392 = 0.05245730360380338\n",
      "cost of iteration: 393 = 0.05246817683400182\n",
      "cost of iteration: 394 = 0.05247911331168735\n",
      "cost of iteration: 395 = 0.052490112231929086\n",
      "cost of iteration: 396 = 0.05250117280046772\n",
      "cost of iteration: 397 = 0.05251229423354976\n",
      "cost of iteration: 398 = 0.0525234757577646\n",
      "cost of iteration: 399 = 0.05253471660988421\n",
      "cost of iteration: 400 = 0.05254601603670565\n",
      "cost of iteration: 401 = 0.05255737329489618\n",
      "cost of iteration: 402 = 0.05256878765084111\n",
      "cost of iteration: 403 = 0.05258025838049406\n",
      "cost of iteration: 404 = 0.052591784769229905\n",
      "cost of iteration: 405 = 0.05260336611170023\n",
      "cost of iteration: 406 = 0.05261500171169118\n",
      "cost of iteration: 407 = 0.05262669088198378\n",
      "cost of iteration: 408 = 0.05263843294421662\n",
      "cost of iteration: 409 = 0.05265022722875103\n",
      "cost of iteration: 410 = 0.05266207307453829\n",
      "cost of iteration: 411 = 0.052673969828989385\n",
      "cost of iteration: 412 = 0.052685916847846896\n",
      "cost of iteration: 413 = 0.05269791349505903\n",
      "cost of iteration: 414 = 0.05270995914265592\n",
      "cost of iteration: 415 = 0.05272205317062795\n",
      "cost of iteration: 416 = 0.0527341949668063\n",
      "cost of iteration: 417 = 0.05274638392674534\n",
      "cost of iteration: 418 = 0.05275861945360728\n",
      "cost of iteration: 419 = 0.05277090095804862\n",
      "cost of iteration: 420 = 0.052783227858108586\n",
      "cost of iteration: 421 = 0.052795599579099545\n",
      "cost of iteration: 422 = 0.05280801555349926\n",
      "cost of iteration: 423 = 0.0528204752208449\n",
      "cost of iteration: 424 = 0.05283297802762902\n",
      "cost of iteration: 425 = 0.05284552342719719\n",
      "cost of iteration: 426 = 0.05285811087964746\n",
      "cost of iteration: 427 = 0.05287073985173141\n",
      "cost of iteration: 428 = 0.05288340981675705\n",
      "cost of iteration: 429 = 0.05289612025449326\n",
      "cost of iteration: 430 = 0.05290887065107582\n",
      "cost of iteration: 431 = 0.052921660498915175\n",
      "cost of iteration: 432 = 0.05293448929660562\n",
      "cost of iteration: 433 = 0.05294735654883609\n",
      "cost of iteration: 434 = 0.052960261766302384\n",
      "cost of iteration: 435 = 0.052973204465621\n",
      "cost of iteration: 436 = 0.052986184169244305\n",
      "cost of iteration: 437 = 0.052999200405377075\n",
      "cost of iteration: 438 = 0.053012252707894586\n",
      "cost of iteration: 439 = 0.053025340616262046\n",
      "cost of iteration: 440 = 0.05303846367545522\n",
      "cost of iteration: 441 = 0.05305162143588254\n",
      "cost of iteration: 442 = 0.0530648134533084\n",
      "cost of iteration: 443 = 0.05307803928877781\n",
      "cost of iteration: 444 = 0.053091298508542245\n",
      "cost of iteration: 445 = 0.05310459068398667\n",
      "cost of iteration: 446 = 0.05311791539155795\n",
      "cost of iteration: 447 = 0.05313127221269413\n",
      "cost of iteration: 448 = 0.053144660733755185\n",
      "cost of iteration: 449 = 0.053158080545954736\n",
      "cost of iteration: 450 = 0.053171531245292857\n",
      "cost of iteration: 451 = 0.0531850124324901\n",
      "cost of iteration: 452 = 0.05319852371292247\n",
      "cost of iteration: 453 = 0.05321206469655753\n",
      "cost of iteration: 454 = 0.05322563499789151\n",
      "cost of iteration: 455 = 0.05323923423588739\n",
      "cost of iteration: 456 = 0.053252862033914106\n",
      "cost of iteration: 457 = 0.053266518019686564\n",
      "cost of iteration: 458 = 0.053280201825206715\n",
      "cost of iteration: 459 = 0.05329391308670559\n",
      "cost of iteration: 460 = 0.05330765144458618\n",
      "cost of iteration: 461 = 0.05332141654336729\n",
      "cost of iteration: 462 = 0.05333520803162822\n",
      "cost of iteration: 463 = 0.053349025561954394\n",
      "cost of iteration: 464 = 0.053362868790883804\n",
      "cost of iteration: 465 = 0.05337673737885429\n",
      "cost of iteration: 466 = 0.05339063099015169\n",
      "cost of iteration: 467 = 0.053404549292858705\n",
      "cost of iteration: 468 = 0.05341849195880474\n",
      "cost of iteration: 469 = 0.053432458663516307\n",
      "cost of iteration: 470 = 0.053446449086168385\n",
      "cost of iteration: 471 = 0.05346046290953645\n",
      "cost of iteration: 472 = 0.0534744998199492\n",
      "cost of iteration: 473 = 0.05348855950724215\n",
      "cost of iteration: 474 = 0.05350264166471179\n",
      "cost of iteration: 475 = 0.05351674598907058\n",
      "cost of iteration: 476 = 0.0535308721804025\n",
      "cost of iteration: 477 = 0.053545019942119416\n",
      "cost of iteration: 478 = 0.05355918898091799\n",
      "cost of iteration: 479 = 0.05357337900673738\n",
      "cost of iteration: 480 = 0.0535875897327174\n",
      "cost of iteration: 481 = 0.053601820875157476\n",
      "cost of iteration: 482 = 0.05361607215347621\n",
      "cost of iteration: 483 = 0.053630343290171426\n",
      "cost of iteration: 484 = 0.05364463401078095\n",
      "cost of iteration: 485 = 0.053658944043843894\n",
      "cost of iteration: 486 = 0.053673273120862605\n",
      "cost of iteration: 487 = 0.053687620976265074\n",
      "cost of iteration: 488 = 0.053701987347368016\n",
      "cost of iteration: 489 = 0.05371637197434037\n",
      "cost of iteration: 490 = 0.05373077460016752\n",
      "cost of iteration: 491 = 0.0537451949706159\n",
      "cost of iteration: 492 = 0.05375963283419807\n",
      "cost of iteration: 493 = 0.053774087942138594\n",
      "cost of iteration: 494 = 0.05378856004834004\n",
      "cost of iteration: 495 = 0.05380304890934981\n",
      "cost of iteration: 496 = 0.053817554284327176\n",
      "cost of iteration: 497 = 0.053832075935011055\n",
      "cost of iteration: 498 = 0.0538466136256881\n",
      "cost of iteration: 499 = 0.05386116712316126\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ec8448c748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "theta=GD(xtrain,ytrain,alpha=0.2,progress=True,iteration=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could see that the cost decreased with each iteration suggesting that our model is working correctly. It stops when the stopping criteria is met, which is 1000 iterations in this case. And finally we can conclude looking at the plot that cost value went down with each iteration. We can further note how the cost drasticallywent  down in the first 100 iterations after which the decrease became negligible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.51977242e-01,  1.49360912e-01,  2.87747478e-01,  1.18627618e-01,\n",
       "        4.04430536e-02,  1.62290192e-01, -1.22787931e-01, -3.01791496e-01,\n",
       "        8.41479162e-02, -9.05407926e-02, -1.35578187e-01,  1.32009350e-01,\n",
       "       -1.65194685e-01, -4.72247566e-03, -1.66982709e-01,  2.93145253e-02,\n",
       "       -8.36295784e-02, -3.53101119e-02, -1.62826302e-02,  6.12012014e-02,\n",
       "       -1.70050313e-01,  8.40955915e-02,  9.48762463e-02,  2.18887773e-01,\n",
       "        3.27014547e-02,  2.63850050e-01,  6.41788888e-02,  5.98004607e-01,\n",
       "        6.24455515e-01,  6.72034877e-01, -4.85853757e+00])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=hypothesis(theta,xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=(prediction>0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model performance and comparision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8AL0OzxdSWZg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.798993227259247"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(ytest,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9992275552122467"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytest,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7349397590361445"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(ytest,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R5lgd0PpSWZj"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YNDoRNwcSWZm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7989756402033201"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr=LogisticRegression()\n",
    "logr.fit(xtrain,ytrain)\n",
    "logr_pred=logr.predict(xtest)\n",
    "roc_auc_score(ytest,logr.predict(xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B3iLC4FlSWZo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9991924440855307"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytest,logr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KCou2M1vSWZw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7261904761904762"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(ytest,logr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    56860\n",
       "1      102\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IAoH7WzmSWZ0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[56855,     5],\n",
       "       [   41,    61]], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(ytest,logr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KkIw4XlhSWZ3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[56857,     3],\n",
       "       [   41,    61]], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(ytest,prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t5BxlWeTSWaf"
   },
   "source": [
    " # References\n",
    "- https://stackoverflow.com/questions/38125319/python-divide-by-zero-encountered-in-log-logistic-regression\n",
    "- https://www.coursera.org/learn/machine-learning/\n",
    "- https://www.kaggle.com/mlg-ulb/creditcardfraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ADWJXqIhSWah"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Vectorized Log.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
